---
title: "a 3D IC Tier Partitioning of Memory Macros: PPA vs. Thermal Tradeoffs"
authors: "Lingjun Zhu, Nesara Eranna Bethur, Yi-Chen Lu, Youngsang Cho, Yunhyeok Im, Sung Kyu Lim"
collection: publications
permalink: /publication/2022-08-01-ISLPED22
excerpt: 'In this paper, we evaluate and quantify the impacts of various macro partitioning on the performance and temperature in commercial-grade 3D ICs. In addition, we propose a set of partitioning guidelines and a quick constraint-graph-based approach to create floorplans for logic-on-memory 3D ICs.''
date: 2022-08-01
venue: 'ACM HyperText'
paperurl: <!-- '[http://academicpages.github.io/files/paper1.pdf](https://dl.acm.org/doi/10.1145/3465336.3475098)' -->
citation: 'Angana Borah, Manash Pratim Barman, Amit C Awekar. (2021). &quot;Are Word Embedding Methods Stable and Should We Care About It?&quot; <i>In Proceedings of the 32nd ACM Conference on Hypertext and Social Media </i>. (pp. 45-55).'
---
<!-- This paper is about the number 2. The number 3 is left for future work. -->

[Download paper here](https://dl.acm.org/doi/10.1145/3465336.3475098)

<!-- Recommended citation: Angana Borah, Manash Pratim Barman, Amit C Awekar. (2021). "Are Word Embedding Methods Stable and Should We Care About It?" <i>In Proceedings of the 32nd ACM Conference on Hypertext and Social Media </i>. (pp. 45-55). -->


The central idea of this paper is to explore the stability measurement of WEMs using intrinsic evaluation based on word similarity. We experiment with three popular WEMs: Word2Vec, GloVe, and fastText. For stability measurement, we investigate the effect of five parameters involved in training these models. We perform experiments using four real-world datasets from different domains: Wikipedia, News, Song lyrics, and European parliament proceedings. We also observe the effect of WEM stability on two downstream tasks: Clustering and Fairness evaluation. Our experiments indicate that amongst the three WEMs, fastText is the most stable, followed by GloVe and Word2Vec.
